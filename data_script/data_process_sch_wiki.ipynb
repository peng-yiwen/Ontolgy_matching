{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from urllib.parse import urlparse\n",
    "import pandas as pd\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "from xml.sax.saxutils import quoteattr\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import re\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* crawl equivalence_class mappings through SPARQL Endpoint: https://query.wikidata.org/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```jsx\n",
    "SELECT ?wd ?wdLabel ?corrName ?schema\n",
    "{\n",
    "  values (?corr ?corrName)\n",
    "    {\n",
    "      (wdt:P1709 \"equivClass\")\n",
    "    }\n",
    "  ?wd ?corr ?schema\n",
    "  filter(regex(str(?schema), \"schema.org\"))\n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\". }\n",
    "} order by ?wd ?schema\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* preparation of wikidata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wikidata_class subset\n",
    "urls = pd.read_csv('equivalent_class.csv')['wd'].values\n",
    "wd_class_subset = []\n",
    "for url in urls:\n",
    "    wd_class_subset.append(Path(urlparse(url).path).stem)\n",
    "# wd_class_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 370/370 [02:07<00:00,  2.90it/s]\n"
     ]
    }
   ],
   "source": [
    "sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\", \n",
    "                       agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36')\n",
    "\n",
    "with open('wd_class_subset.csv', 'w') as f:\n",
    "    writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_ALL)\n",
    "    line = ['Qid', 'Label', 'Description', 'AliasList', 'PropertyList']\n",
    "    writer.writerow(line)\n",
    "\n",
    "    for classItem in tqdm(wd_class_subset):\n",
    "        query = \"\"\"\n",
    "            PREFIX wd: <http://www.wikidata.org/entity/>\n",
    "            PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "            PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "            PREFIX skos: <http://www.w3.org/2004/02/skos/core#>\n",
    "            PREFIX schema: <http://schema.org/>\n",
    "\n",
    "            SELECT DISTINCT ?Qid ?Label ?Description (GROUP_CONCAT(DISTINCT ?Alias; SEPARATOR=\" | \") AS ?AliasList) (GROUP_CONCAT(DISTINCT ?propertyLabel; SEPARATOR=\" | \") AS ?PropertyList)\n",
    "            WHERE {\n",
    "            BIND(wd:%s AS ?Qid)\n",
    "\n",
    "            # Retrieve additional information for each class\n",
    "            ?Qid rdfs:label ?Label FILTER (lang(?Label) = \"en\").\n",
    "            OPTIONAL { ?Qid schema:description ?Description FILTER (lang(?Description) = \"en\").}\n",
    "            OPTIONAL { ?Qid skos:altLabel ?Alias FILTER (lang(?Alias) = \"en\"). }\n",
    "            OPTIONAL { \n",
    "                ?Qid wdt:P1963 ?property.\n",
    "                ?property rdfs:label ?propertyLabel FILTER (lang(?propertyLabel) = \"en\"). \n",
    "                }\n",
    "            } \n",
    "            GROUP BY ?Qid ?Label ?Description\n",
    "                \"\"\"%(classItem)\n",
    "        \n",
    "        sparql.setQuery(query)\n",
    "        sparql.setReturnFormat(JSON)\n",
    "        results=sparql.query().convert()\n",
    "    \n",
    "        for row in results[\"results\"][\"bindings\"]:\n",
    "            # wikiclass = Path(urlparse(row['Qid']['value']).path).stem\n",
    "            wikiclass = str(row['Qid']['value'])\n",
    "            label = str(row['Label']['value'])\n",
    "            description = str(row['Description']['value']) if 'Description' in row.keys() else None\n",
    "            alias = str(row['AliasList']['value']).split(\" | \") if 'AliasList' in row.keys() else None\n",
    "            properti = str(row['PropertyList']['value']).split(\" | \") if 'PropertyList' in row.keys() else None\n",
    "            # print(wikiclass, label, description, alias, properti)\n",
    "            writer.writerow([wikiclass, label, description, alias, properti])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* preparation of schema data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_type = r'<https://schema\\.org/(.*?)> <http://www\\.w3\\.org/1999/02/22-rdf-syntax-ns#type> <https://schema\\.org/(.*?)> \\.'\n",
    "pattern_subclass = r'<https://schema\\.org/(.*?)> <http://www\\.w3\\.org/2000/01/rdf-schema#subClassOf> <https://schema\\.org/(.*?)> \\.'\n",
    "\n",
    "with open('schemaorg-current-https.nt', 'r') as fin, open('sch_types_all.txt', 'w', encoding=\"utf-8\") as fout:\n",
    "    for line in fin:\n",
    "        line = line.strip() \n",
    "        match_type =  re.match(pattern_type, line)\n",
    "        match_subclass = re.match(pattern_subclass, line)\n",
    "        \n",
    "        if match_type:\n",
    "            # print('1', match_type.group(1), match_type.group(2))\n",
    "            fout.write(match_type.group(1) + '\\t' + match_type.group(2) + '\\n')\n",
    "        if match_subclass:\n",
    "            # print('2', match_subclass.group(1), match_subclass.group(2))\n",
    "            fout.write(match_subclass.group(1) + '\\t' + match_subclass.group(2) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>child</th>\n",
       "      <th>parent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EventMovedOnline</td>\n",
       "      <td>EventStatusType</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MedicalSignOrSymptom</td>\n",
       "      <td>MedicalCondition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DoseSchedule</td>\n",
       "      <td>MedicalIntangible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MedicalSign</td>\n",
       "      <td>MedicalSignOrSymptom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Paperback</td>\n",
       "      <td>BookFormatType</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  child                parent\n",
       "0      EventMovedOnline       EventStatusType\n",
       "1  MedicalSignOrSymptom      MedicalCondition\n",
       "2          DoseSchedule     MedicalIntangible\n",
       "3           MedicalSign  MedicalSignOrSymptom\n",
       "4             Paperback        BookFormatType"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('sch_types_all.txt', delimiter='\\t', names=['child', 'parent']).head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* cleaning schema_types: removing all subclasses of DataType (including DataType)\n",
    "* cleaning referenced mappings and wd_subset_classes: removing types/classes which schema_types don't contain\n",
    "* one-to-one mapping filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_children(df, parent_class, children=[], height=0):\n",
    "    '''\n",
    "    @param: df: dataframe with (parent_class, child_class) as index\n",
    "            children: all children for input parent_class\n",
    "            height: hierarchy height for the input parent_class\n",
    "    '''\n",
    "    max_height = height # note the maximum height\n",
    "    _children = children.copy()\n",
    "    # get all direct children\n",
    "    idx = pd.IndexSlice\n",
    "    if parent_class in df.index.get_level_values('parent'):\n",
    "        rows = df.loc[idx[parent_class, :], :]\n",
    "        new_children = rows.index.get_level_values('child').unique().tolist()\n",
    "\n",
    "        # get children of new_children\n",
    "        for child in new_children:\n",
    "            if child not in _children:\n",
    "                _children.append(child)\n",
    "                #print(1, _children)\n",
    "                _children, child_depth = find_all_children(df, child, _children, height+1)\n",
    "                #print(2, _children, child_depth)\n",
    "                if child_depth > max_height:\n",
    "                    max_height = child_depth\n",
    "\n",
    "    return _children, max_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sch_types = pd.read_csv('sch_types_all.txt', delimiter='\\t', names=['child', 'parent']).set_index(['parent', 'child'])\n",
    "remove_types, _ = find_all_children(df_sch_types, 'DataType')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_schema = pd.read_csv('schemaorg-current-https-types.csv')\n",
    "df_schema = df_schema[~df_schema['label'].isin(remove_types)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_comment(text):\n",
    "    # remove some html \n",
    "    clean_data = re.sub(r'<[^>]+>', '', text)\n",
    "\n",
    "    # change some particular symbol\n",
    "    clean_data = re.sub(r\"&lt;\", \"<\", clean_data)\n",
    "    clean_data = re.sub(r\"&gt;\", \">\", clean_data)\n",
    "    clean_data = re.sub(r\"&#x2014;\", \"—\", clean_data)\n",
    "\n",
    "    # remove some additional spaces\n",
    "    clean_data = re.sub(r'\\s+', ' ', clean_data)\n",
    "    clean_data = re.sub(r'^\\s+|\\s+?$', '', clean_data)\n",
    "    clean_data = re.sub(r'\\n', '', clean_data)\n",
    "    return clean_data\n",
    "\n",
    "def clean_Type(URIString):\n",
    "    typeURIs = URIString.split(',')\n",
    "    return [Path(urlparse(type_).path).stem for type_ in typeURIs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://schema.org/3DModel</td>\n",
       "      <td>3DModel</td>\n",
       "      <td>A 3D model represents some kind of 3D content,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://schema.org/AMRadioChannel</td>\n",
       "      <td>AMRadioChannel</td>\n",
       "      <td>A radio channel that uses AM.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://schema.org/APIReference</td>\n",
       "      <td>APIReference</td>\n",
       "      <td>Reference documentation for application progra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://schema.org/Abdomen</td>\n",
       "      <td>Abdomen</td>\n",
       "      <td>Abdomen clinical examination.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://schema.org/AboutPage</td>\n",
       "      <td>AboutPage</td>\n",
       "      <td>Web page type: About page.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  id           label  \\\n",
       "0         https://schema.org/3DModel         3DModel   \n",
       "1  https://schema.org/AMRadioChannel  AMRadioChannel   \n",
       "2    https://schema.org/APIReference    APIReference   \n",
       "3         https://schema.org/Abdomen         Abdomen   \n",
       "4       https://schema.org/AboutPage       AboutPage   \n",
       "\n",
       "                                             comment  \n",
       "0  A 3D model represents some kind of 3D content,...  \n",
       "1                      A radio channel that uses AM.  \n",
       "2  Reference documentation for application progra...  \n",
       "3                      Abdomen clinical examination.  \n",
       "4                         Web page type: About page.  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_schema.loc[:, \"comment\"] = df_schema.loc[:, \"comment\"].apply(lambda x: clean_comment(x))\n",
    "# df_schema[\"subTypeOf\"] = df_schema[\"subTypeOf\"].apply(lambda x: clean_Type(x) if str(x) != 'nan' else x)\n",
    "# df_schema[\"properties\"] = df_schema[\"properties\"].apply(lambda x: clean_Type(x) if str(x) != 'nan' else x)\n",
    "\n",
    "df_schema_desc = df_schema.loc[:, ['id', 'label', 'comment']]\n",
    "df_schema_desc.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* cleaning referenced mappings and wd_subset_classes: removing types/classes which schema types don't contain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_map = pd.read_csv('equivalent_class.csv')\n",
    "df_wd_sub_classes = pd.read_csv('wd_class_subset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_map['schema_label'] = df_map['schema'].apply(lambda x: Path(urlparse(x).path).stem)\n",
    "# df_map['wd'] = df_map['wd'].apply(lambda x: Path(urlparse(x).path).stem)\n",
    "df_map1 = df_map[df_map['schema'].isin(df_schema_desc['id'].values)] # removing mappings of DataType\n",
    "df_cleaned_map = df_map1[df_map1['wd'].isin(df_wd_sub_classes['Qid'].values)] # removing mappings which have no wiki labels\n",
    "df_cleaned_wd_sub_classes = df_wd_sub_classes[df_wd_sub_classes['Qid'].isin(df_cleaned_map['wd'])]\n",
    "\n",
    "df_cleaned_wd_sub_classes = df_cleaned_wd_sub_classes.rename(columns={'Qid': 'id', 'Label':'label', 'Description':'comment'})\n",
    "df_cleaned_wd_sub_classes.reset_index(drop=True, inplace=True)\n",
    "df_cleaned_map.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Removing 2-to-1 mappings\n",
    "# Here only consider 1-to-1 mappings\n",
    "Del=['ImageObject', 'PublicationVolume', 'Quotation','EntertainmentBusiness', 'EventVenue']\n",
    "df_cleaned_mapping = df_cleaned_map[~df_cleaned_map['schema_label'].isin(Del)]\n",
    "df_cleaned_mapping.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df_cleaned_wd = df_cleaned_wd_sub_classes[df_cleaned_wd_sub_classes['id'].isin(df_cleaned_mapping['wd'].to_list())].drop_duplicates()\n",
    "df_cleaned_wd.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df_cleaned_schema = df_schema_desc[df_schema_desc['id'].isin(df_cleaned_mapping['schema'].to_list())].drop_duplicates()\n",
    "df_cleaned_schema.reset_index(drop=True, inplace=True)\n",
    "# df_map_reference['wd_desc'].fillna('', inplace=True) # deal with NaN value in wiki_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned_wd['comment'].fillna('', inplace=True) # deal with NaN value in wiki_desc\n",
    "df_cleaned_schema['comment'].fillna('', inplace=True) # deal with NaN value in schema_desc\n",
    "df_cleaned_mapping = df_cleaned_mapping.rename(columns={'wd':'Class1_id', 'schema':'Class2_id', 'corrName':'Relation'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # output the cleaned files\n",
    "# df_cleaned_schema.to_csv('target.csv', index=False)\n",
    "# df_cleaned_mapping.loc[:, ['Class1_id', 'Class2_id', 'Relation']].to_csv('reference.csv', index=False)\n",
    "# df_cleaned_wd.loc[:, ['id', 'label', 'comment']].to_csv('source.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* generate expended dataset for robustness test: discussion in paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_schema = pd.read_csv('schemaorg-current-https-types.csv')\n",
    "df_schema.loc[:, \"comment\"] = df_schema.loc[:, \"comment\"].apply(lambda x: clean_comment(x))\n",
    "df_schema_desc = df_schema.loc[:, ['id', 'label', 'comment']]\n",
    "df_schema_desc.to_csv('noised_target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2791549"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # the number of the whole classes in Wikidata\n",
    "# a = pd.read_csv('classes.txt', delimiter=' ', names=['child', 'parent'])\n",
    "# len(set(a['child'].unique()).union(set(a['parent'].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Set data to OAEI standard format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph, URIRef, Literal, RDF, XSD\n",
    "from rdflib.namespace import OWL, RDF, RDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference alignment to OAEI rdf format\n",
    "def get_file_header():\n",
    "    return \"\"\"<?xml version=\\\"1.0\\\" encoding=\\\"utf-8\\\"?>\n",
    "    <rdf:RDF xmlns=\"http://knowledgeweb.semanticweb.org/heterogeneity/alignment\"\n",
    "      xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"\n",
    "      xmlns:xsd=\"http://www.w3.org/2001/XMLSchema#\">\n",
    "<Alignment>\n",
    "  <xml>yes</xml>\n",
    "  <level>0</level>\n",
    "  <type>??</type>\"\"\"\n",
    "\n",
    "def get_mapping_format(source, target, measure):\n",
    "    relation= '='\n",
    "    return \"\"\"\n",
    "  <map>\n",
    "    <Cell>\n",
    "      <entity1 rdf:resource=%s/>\n",
    "      <entity2 rdf:resource=%s/>\n",
    "      <relation>%s</relation>\n",
    "      <measure rdf:datatype=\"xsd:float\">%.1f</measure>\n",
    "    </Cell>\n",
    "  </map>\"\"\" %(quoteattr(source), quoteattr(target), '=', float(measure))\n",
    "#(quoteattr(source), quoteattr(target), relation, measure)\n",
    "\n",
    "def _get_file_footer():\n",
    "    return \"\"\"\n",
    "  </Alignment>\n",
    "</rdf:RDF>\n",
    "\"\"\"\n",
    "\n",
    "def writeAlignments(file, df):\n",
    "    #df=pd.read_csv(alignments)\n",
    "    #df=df.drop_duplicates(subset=['Class_Name_1', 'Class_Name_2'], keep='first')\n",
    "\n",
    "    with open(file, 'w', encoding='utf-8') as Myfile:\n",
    "        Myfile.write(get_file_header())\n",
    "        for i in range(len(df)):\n",
    "            Myfile.write(get_mapping_format(df.loc[i,'Class1_id'], df.loc[i,'Class2_id'],'1.0'))\n",
    "        Myfile.write(_get_file_footer())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "FilePath ='reference.rdf'\n",
    "writeAlignments(FilePath, df_cleaned_mapping.loc[:, ['Class1_id', 'Class2_id', 'Relation']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate source/target ontology\n",
    "# source dataframe: df_cleaned_wd\n",
    "# target dataframe: df_cleaned_schema\n",
    "graph = Graph()\n",
    "graph.bind(\"owl\", OWL)\n",
    "graph.bind(\"rdfs\", RDFS)\n",
    "\n",
    "for i in df_cleaned_wd.index:\n",
    "    #adding classes to the graph\n",
    "    classN = URIRef(df_cleaned_wd.loc[i,'id'])\n",
    "    name = Literal(df_cleaned_wd.loc[i, 'label'], datatype=XSD['string']) #the class name label\n",
    "    desc = Literal(df_cleaned_wd.loc[i, 'comment'], datatype=XSD['string']) #the class description\n",
    "    graph.add((classN, RDF.type, OWL.Class))\n",
    "    graph.add((classN, RDFS.label, name))\n",
    "    graph.add((classN, RDFS.comment, desc))\n",
    "\n",
    "outFile = 'source.rdf'\n",
    "with open(outFile, 'wb') as f:\n",
    "    graph.serialize(f, format='xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Graph()\n",
    "graph.bind(\"owl\", OWL)\n",
    "graph.bind(\"rdfs\", RDFS)\n",
    "\n",
    "for i in df_cleaned_schema.index:\n",
    "    #adding classes to the graph\n",
    "    classN = URIRef(df_cleaned_schema.loc[i,'id'])\n",
    "    name = Literal(df_cleaned_schema.loc[i, 'label'], datatype=XSD['string']) #the class name label\n",
    "    desc = Literal(df_cleaned_schema.loc[i, 'comment'], datatype=XSD['string']) #the class description\n",
    "    graph.add((classN, RDF.type, OWL.Class))\n",
    "    graph.add((classN, RDFS.label, name))\n",
    "    graph.add((classN, RDFS.comment, desc))\n",
    "\n",
    "outFile = 'target.rdf'\n",
    "with open(outFile, 'wb') as f:\n",
    "    graph.serialize(f, format='xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "343\n"
     ]
    }
   ],
   "source": [
    "# check the number of classes\n",
    "classes=[]\n",
    "for s, p, o in graph.triples((None, RDF.type, OWL.Class)):\n",
    "    classes.append(str(s))\n",
    "s=set(classes)\n",
    "print(len(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
